{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to /home/coder/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/coder/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/coder/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/coder/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import nltk\n",
    "from datasets import load_dataset\n",
    "from gensim.models import Word2Vec, LdaModel, Doc2Vec\n",
    "from gensim import corpora\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.utils import simple_preprocess\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from sentence_transformers.evaluation import BinaryClassificationEvaluator\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding, TrainingArguments, Trainer\n",
    "\n",
    "from utils import find_best_acc_and_threshold, find_best_f1_and_threshold\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d1d226cf9b1e49b8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Text Similarity using Natural Language Processing\n",
    "\n",
    "In NLP, one of the fundamental tasks is measuring the similarity between texts. Text similarity, in essence, is the process of quantifying how alike two or more pieces of text are in terms of their content, meaning, or structure.\n",
    "\n",
    "In this notebook, we will explore the concept of text similarity, which often boils down to understanding the similarity between sentences. \n",
    "\n",
    "To demonstrate and experiment with text similarity techniques, we will utilize the [Microsoft Research Paraphrase Corpus](https://www.microsoft.com/en-us/download/details.aspx?id=52398) dataset. This dataset is a part of the [GLUE](https://gluebenchmark.com/) (General Language Understanding Evaluation benchmark) and contains pairs of sentences, each associated with a label indicating whether the texts are semantically equivalent.\n",
    "\n",
    "Let's begin by loading the dataset and taking a closer look at its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc3e2ae873035cae",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"glue\", \"mrpc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cb37cb079bd5ea3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dataset = dataset['train'].with_format('torch')\n",
    "valid_dataset = dataset['validation'].with_format('torch')\n",
    "test_dataset = dataset['test'].with_format('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42d6592d4175528e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': Value(dtype='string', id=None),\n",
       " 'sentence2': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=['not_equivalent', 'equivalent'], id=None),\n",
       " 'idx': Value(dtype='int32', id=None)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.features # show features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d55b068513656aa",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amrozi accused his brother , whom he called \" ...</td>\n",
       "      <td>Referring to him as only \" the witness \" , Amr...</td>\n",
       "      <td>tensor(1)</td>\n",
       "      <td>tensor(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yucaipa owned Dominick 's before selling the c...</td>\n",
       "      <td>Yucaipa bought Dominick 's in 1995 for $ 693 m...</td>\n",
       "      <td>tensor(0)</td>\n",
       "      <td>tensor(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They had published an advertisement on the Int...</td>\n",
       "      <td>On June 10 , the ship 's owners had published ...</td>\n",
       "      <td>tensor(1)</td>\n",
       "      <td>tensor(2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Around 0335 GMT , Tab shares were up 19 cents ...</td>\n",
       "      <td>Tab shares jumped 20 cents , or 4.6 % , to set...</td>\n",
       "      <td>tensor(0)</td>\n",
       "      <td>tensor(3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The stock rose $ 2.11 , or about 11 percent , ...</td>\n",
       "      <td>PG &amp; E Corp. shares jumped $ 1.63 or 8 percent...</td>\n",
       "      <td>tensor(1)</td>\n",
       "      <td>tensor(4)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence1  \\\n",
       "0  Amrozi accused his brother , whom he called \" ...   \n",
       "1  Yucaipa owned Dominick 's before selling the c...   \n",
       "2  They had published an advertisement on the Int...   \n",
       "3  Around 0335 GMT , Tab shares were up 19 cents ...   \n",
       "4  The stock rose $ 2.11 , or about 11 percent , ...   \n",
       "\n",
       "                                           sentence2      label        idx  \n",
       "0  Referring to him as only \" the witness \" , Amr...  tensor(1)  tensor(0)  \n",
       "1  Yucaipa bought Dominick 's in 1995 for $ 693 m...  tensor(0)  tensor(1)  \n",
       "2  On June 10 , the ship 's owners had published ...  tensor(1)  tensor(2)  \n",
       "3  Tab shares jumped 20 cents , or 4.6 % , to set...  tensor(0)  tensor(3)  \n",
       "4  PG & E Corp. shares jumped $ 1.63 or 8 percent...  tensor(1)  tensor(4)  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_dataset).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b102543ecb1d43e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot labels distribution as percentage\n",
    "pd.Series(train_dataset['label'].numpy()).value_counts(normalize=True).plot(kind='bar')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f5dc876da0b116a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "As we can see, the dataset is unbalanced."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e4609daf2ad916c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6265fed0bae20a84",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "punctuation = string.punctuation\n",
    "\n",
    "def preprocess_dataset(ds):\n",
    "    # tokenize\n",
    "    return ds.map(lambda x: {'sentence1': simple_preprocess(x['sentence1']), 'sentence2': simple_preprocess(x['sentence2'])})\n",
    "\n",
    "preprocessed_train_dataset = preprocess_dataset(train_dataset)\n",
    "preprocessed_test_dataset = preprocess_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "379d0f928b099e86",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict(model, ds):\n",
    "    return model(ds['sentence1'], ds['sentence2'])\n",
    "\n",
    "def score(labels, scores):\n",
    "    \"\"\"\n",
    "    Calculate the best accuracy and the best F1-score for given labels and scores. \n",
    "    The best accuracy is the accuracy when the threshold is chosen to maximize the accuracy.\n",
    "    Likewise for F1-score.\n",
    "    \n",
    "    :param labels: Ground truth labels (0 or 1)\n",
    "    :param scores: Cosine similarity scores of embeddings\n",
    "    :return Returns the prediction with the best accuracy\n",
    "    \"\"\"\n",
    "    acc, t1 = find_best_acc_and_threshold(scores, labels, True)\n",
    "    f1, _, _, t2 = find_best_f1_and_threshold(scores, labels, True)\n",
    "    print(f'Best Accuracy: {acc:.4f} (threshold={t1:.4f})')\n",
    "    print(f'Best F1: {f1:.4f} (threshold={t2:.4f})')\n",
    "    return scores > t1\n",
    "    \n",
    "def abs_score(labels, scores):\n",
    "    acc = accuracy_score(labels, scores)\n",
    "    f1 = f1_score(labels, scores)\n",
    "    print(f'Accuracy: {acc:.4f}')\n",
    "    print(f'F1: {f1:.4f}')\n",
    "    return scores == 1\n",
    "\n",
    "preds = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3bfc71d1d0e7af5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Approaches\n",
    "### 1 TF-IDF\n",
    "\n",
    "For this approach let's calculate tf-idf vectors of texts and compare them using cosine similarity. We will use `scikit-learn` and `nltk` for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a146c178b376926c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:489: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", '``', 'could', 'might', 'must', \"n't\", 'need', 'sha', 'wo', 'would'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n",
       "                            'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
       "                            \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n",
       "                            'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
       "                            'her', 'hers', 'herself', 'it', \"it's\", 'its',\n",
       "                            'itself', ...],\n",
       "                tokenizer=<function word_tokenize at 0x7f0fb7d6db80>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=nltk.word_tokenize, stop_words=stopwords + list(punctuation))\n",
    "vectorizer.fit(train_dataset['sentence1'] + train_dataset['sentence2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f47378ba601b9fa4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tf_idf_model(sentences1, sentences2):\n",
    "    tf_idf1 = vectorizer.transform(sentences1)\n",
    "    tf_idf2 = vectorizer.transform(sentences2)\n",
    "    return torch.tensor(cosine_similarity(tf_idf1, tf_idf2).diagonal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38cd9deb174657b6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.7072 (threshold=0.4930)\n",
      "Best F1: 0.8144 (threshold=0.3834)\n"
     ]
    }
   ],
   "source": [
    "preds['tfidf'] = predict(tf_idf_model, test_dataset)\n",
    "preds['tfidf'] = score(test_dataset['label'], preds['tfidf'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a84bf4c239a5595",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "For such a simple approach this not too bad. This is going to be our baseline. Let's try to improve."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b081a95e570b027d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2 BLEU-score\n",
    "Let's try using BLEU-score as a metric of similarity of two texts. We will use `nltk` for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e407db64e6ef908",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bleu_score_model(sentences1, sentences2):\n",
    "    res = []\n",
    "    for sentence1, sentence2 in zip(sentences1, sentences2):\n",
    "        res.append(nltk.translate.bleu_score.sentence_bleu([sentence1], sentence2))\n",
    "    return torch.tensor(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "322571ebc1594903",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.7472 (threshold=0.5129)\n",
      "Best F1: 0.8283 (threshold=0.5129)\n"
     ]
    }
   ],
   "source": [
    "preds['bleu'] = predict(bleu_score_model, test_dataset)\n",
    "preds['bleu'] = score(test_dataset['label'], preds['bleu'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f4d009d44c71665",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Wow, this trivial approach is better than TF-IDF."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13a930e322a5b1a0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3 Word Embeddings: Word2Vec\n",
    "Let's try to use word embeddings. We will use Word2Vec embeddings from `gensim` and calculate sentence embeddings as an average of word embeddings. Then we will compare sentence embeddings using cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3c5cea7d855e05f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(preprocessed_train_dataset['sentence1'] + preprocessed_train_dataset['sentence2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fba12cd1e66c627f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word2vec = Word2Vec(preprocessed_train_dataset['sentence1'] + preprocessed_train_dataset['sentence2'], min_count=1, epochs=40).wv\n",
    "\n",
    "def word2vec_model(sentences1, sentences2):\n",
    "    res = []\n",
    "    for sentence1, sentence2 in zip(sentences1, sentences2):\n",
    "        res.append(word2vec.n_similarity(sentence1, sentence2))\n",
    "    return torch.tensor(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b18c4724e0c7b3cb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.6754 (threshold=0.6523)\n",
      "Best F1: 0.8015 (threshold=0.4268)\n"
     ]
    }
   ],
   "source": [
    "preds['word2vec'] = predict(word2vec_model, preprocessed_test_dataset)\n",
    "preds['word2vec'] = score(test_dataset['label'], preds['word2vec'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2bf29651b261512e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Well, this approach turned out worse than our baseline."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85f2e7d58a1cc300",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 4 Doc2Vec\n",
    "This is a logical continuation of the previous approach. We will use Doc2Vec embeddings from `gensim`. Like in the previous approach, we will compare sentence embeddings using cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47c719dd7b7ef8e1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc2vec = Doc2Vec(vector_size=100, min_count=1, epochs=100)\n",
    "tagged_corpus = [TaggedDocument(doc, [i]) for i, doc in enumerate(preprocessed_train_dataset['sentence1'] + preprocessed_train_dataset['sentence2'])]\n",
    "doc2vec.build_vocab(tagged_corpus)\n",
    "doc2vec.train(tagged_corpus, total_examples=doc2vec.corpus_count, epochs=doc2vec.epochs)\n",
    "\n",
    "def doc2vec_model(sentences1, sentences2):\n",
    "    res = []\n",
    "    for sentence1, sentence2 in zip(sentences1, sentences2):\n",
    "        res.append(doc2vec.similarity_unseen_docs(sentence1, sentence2))\n",
    "    return torch.tensor(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2f9c26c96474221",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.7020 (threshold=0.3946)\n",
      "Best F1: 0.8049 (threshold=0.1942)\n"
     ]
    }
   ],
   "source": [
    "preds['doc2vec'] = predict(doc2vec_model, preprocessed_test_dataset)\n",
    "preds['doc2vec'] = score(test_dataset['label'], preds['doc2vec'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e789108e08a16e3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Well, we get results comparable to the simplest baseline tf-idf."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "833a3d0c792b6071",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 5 Latent Dirichlet Allocation\n",
    "Let's try LDA. The idea is to represent each sentence as a distribution over topics and then compare these distributions using cosine distance. We will use `gensim` for this task. We will use 10 topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "157c52c633647670",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus1 = [dictionary.doc2bow(sentence) for sentence in preprocessed_train_dataset['sentence1']]\n",
    "corpus2 = [dictionary.doc2bow(sentence) for sentence in preprocessed_train_dataset['sentence2']]\n",
    "train_corpus = corpus1 + corpus2\n",
    "lda = LdaModel(train_corpus, num_topics=10, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c477674239d3198d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lda_model(sentences1, sentences2):\n",
    "    res = []\n",
    "    for sentence1, sentence2 in zip(sentences1, sentences2):\n",
    "        # to bow\n",
    "        bow1 = dictionary.doc2bow(sentence1)\n",
    "        bow2 = dictionary.doc2bow(sentence2)\n",
    "        # to topic distribution\n",
    "        emb1 = lda.get_document_topics(bow1, minimum_probability=0)\n",
    "        emb2 = lda.get_document_topics(bow2, minimum_probability=0)\n",
    "        # to numpy array\n",
    "        emb1 = np.array(emb1)[:, 1]\n",
    "        emb2 = np.array(emb2)[:, 1]\n",
    "        # cosine similarity\n",
    "        res.append(cosine_similarity(emb1.reshape(1, -1), emb2.reshape(1, -1))[0][0])\n",
    "    return torch.tensor(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66143db4a32b3cb7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.6684 (threshold=0.1079)\n",
      "Best F1: 0.7990 (threshold=0.0163)\n"
     ]
    }
   ],
   "source": [
    "preds['lda'] = predict(lda_model, preprocessed_test_dataset)\n",
    "preds['lda'] = score(test_dataset['label'], preds['lda'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5bf3e308e13ef987",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We got a result similar to the previous approaches.\n",
    "\n",
    "Why did this happen? And why have word2vec, doc2vec and LDA do worse than simple tf-idf? I think the reason is in the dataset specifics. The dataset contains *paraphrased* sentences, therefore the sentences are very similar. This means that the average of word embeddings of two sentences will be very similar. To understand the difference between the sentences, we must look at the context of the sentence and specific words that carry a lot of information (like numbers, names, dates, etc.). \n",
    "\n",
    "So basically I think that `word2vec`, `doc2vec` and `LDA` are better suited for tasks where the sentences are not very similar. For example, for determining whether texts share the same topic."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2158b5b71b63214",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Transformer-based approaches\n",
    "To better capture the context let's try to use transformer-based approaches. Transformers are a good choice because they are able to capture the context of the sentence. We will use `transformers` and `sentence-transformers` libraries for this task.\n",
    "### 6 BERT Classifier\n",
    "\n",
    "Let's try using the BERT model. We will use a `BERTClassifier` for two labels (\"texts not equivalent\" and \"texts equivalent\"). We will put both sentences into the model (using the `huggingface` tokenizer) simultaneously. The output of the model will be two neurons for our labels, and we pick the one with the higher value to be the predicted label.\n",
    "\n",
    "![BERTClassifier setup](https://alexkovrigin.me/data/mermaid-diagram-2023-09-15-203138.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63f5efc6ceb77aa2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6da432d8f7cea4e4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75c4122d2208ef03",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25fa5a75d21f1c57",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\"test-trainer\", evaluation_strategy=\"epoch\")\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f55b2fdd885f2db7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "First, let's evaluate the raw model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6893a966a552cc03",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  1/108 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3351\n",
      "F1: 0.0000\n"
     ]
    }
   ],
   "source": [
    "preds['bert'] = torch.tensor(trainer.predict(tokenized_datasets[\"test\"]).predictions.argmax(axis=1))\n",
    "preds['bert'] = abs_score(test_dataset['label'], preds['bert'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d1883c556f3676b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Well, the weights on the last two neurons have not been initialized... Let's try to get a sensible result by fine-tuning the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60461fff5cd00335",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 13/690 00:01 < 01:49, 6.20 it/s, Epoch 0.05/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=690, training_loss=0.3321452182272206, metrics={'train_runtime': 124.6824, 'train_samples_per_second': 88.256, 'train_steps_per_second': 5.534, 'total_flos': 430733353175520.0, 'train_loss': 0.3321452182272206, 'epoch': 3.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27e2d41da43d5899",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8267\n",
      "F1: 0.8758\n"
     ]
    }
   ],
   "source": [
    "preds['bert'] = torch.tensor(trainer.predict(tokenized_datasets[\"test\"]).predictions.argmax(axis=1))\n",
    "preds['bert'] = abs_score(test_dataset['label'], preds['bert'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f76a81573e775be",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The result has improved immensely, making this approach better than any other approach we tried so far!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c76a0c36e9891b83",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 7 Sentence Transformer Embeddings\n",
    "Rather logically, we can also generate embeddings using transformers. For our purposes, we have positive and negative pairs, therefore we can use a Siamese network with contrastive loss. We will use the `sentence-transformers` library for this task.\n",
    "\n",
    "![Sentence Transformer setup](https://alexkovrigin.me/data/mermaid-diagram-2023-09-15-203213.png)\n",
    "\n",
    "Sentence Transformers library is a powerful tool for NLP tasks, including sentence similarity. Furthermore, it has a great interface for fine-tuning models on custom datasets. We will use it to fine-tune a model on the MRPC dataset. We will use the `all-mpnet-base-v2` model and cosine similarity contrastive loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "906ce629d0b9ee5e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c552b16b5c8784c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "First, let's evaluate the raw model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f52f3d36f1fb4efc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def st_model(sentences1, sentences2):\n",
    "    model.eval()\n",
    "    res = []\n",
    "    embeddings = model.encode(sentences1 + sentences2, show_progress_bar=True)\n",
    "    for emb1, emb2 in zip(embeddings[:len(sentences1)], embeddings[len(sentences1):]):\n",
    "        res.append(cosine_similarity(emb1.reshape(1, -1), emb2.reshape(1, -1))[0][0])\n",
    "    return torch.tensor(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "55a90fa139739b31",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 108/108 [00:01<00:00, 88.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.7507 (threshold=0.6873)\n",
      "Best F1: 0.8314 (threshold=0.6384)\n"
     ]
    }
   ],
   "source": [
    "# evaluate acc and f1 on sentence transformer model\n",
    "model.eval()\n",
    "preds['sentence_transformer'] = predict(st_model, test_dataset)\n",
    "preds['sentence_transformer'] = score(test_dataset['label'], preds['sentence_transformer'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70db34f25056304f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This is fine. Let's see what happens when we fine-tune the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57dfb0c223819e6c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_examples = []\n",
    "\n",
    "for example in train_dataset:\n",
    "  train_examples.append(InputExample(texts=[example['sentence1'], example['sentence2']], label=float(example['label'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "38e7e653018cb1d5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=64)\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)\n",
    "num_epochs = 10\n",
    "warmup_steps = int(len(train_dataloader) * num_epochs * 0.1) #10% of train data\n",
    "evaluator = BinaryClassificationEvaluator(valid_dataset['sentence1'], valid_dataset['sentence2'], valid_dataset['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c7c6251826c90b5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 58/58 [00:08<00:00,  6.66it/s]\n",
      "Iteration: 100%|██████████| 58/58 [00:08<00:00,  6.62it/s]\n",
      "Iteration: 100%|██████████| 58/58 [00:08<00:00,  6.67it/s]\n",
      "Iteration: 100%|██████████| 58/58 [00:08<00:00,  6.68it/s]\n",
      "Iteration: 100%|██████████| 58/58 [00:08<00:00,  6.70it/s]\n",
      "Iteration: 100%|██████████| 58/58 [00:08<00:00,  6.54it/s]\n",
      "Iteration: 100%|██████████| 58/58 [00:08<00:00,  6.61it/s]\n",
      "Iteration: 100%|██████████| 58/58 [00:08<00:00,  6.53it/s]\n",
      "Iteration: 100%|██████████| 58/58 [00:08<00:00,  6.63it/s]\n",
      "Iteration: 100%|██████████| 58/58 [00:08<00:00,  6.51it/s]\n",
      "Epoch: 100%|██████████| 10/10 [01:30<00:00,  9.10s/it]\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          epochs=num_epochs,\n",
    "          warmup_steps=warmup_steps,\n",
    "          evaluator=evaluator) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "43a19cc81ad7b93f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 108/108 [00:01<00:00, 84.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.8168 (threshold=0.5908)\n",
      "Best F1: 0.8678 (threshold=0.5908)\n"
     ]
    }
   ],
   "source": [
    "# evaluate acc and f1 on sentence transformer model\n",
    "model.eval()\n",
    "preds['sentence_transformer'] = predict(st_model, test_dataset)\n",
    "preds['sentence_transformer'] = score(test_dataset['label'], preds['sentence_transformer'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "751d2a2e840c580a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Indeed, fine-tuning improved the result.\n",
    "\n",
    "Actually, the highest score overall on the [sentence similarity leaderboard](https://huggingface.co/spaces/mteb/leaderboard) is achieved by a similar (but larger) model [BAAI/bge-large-en-v1.5](https://huggingface.co/BAAI/bge-large-en-v1.5)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c665985aea21af6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "We tried several approaches to the text similarity task. First, we tried simple approaches like tf-idf, BLEU-score as baselines. Then we tried word embeddings (Word2Vec, Doc2Vec) and LDA. Finally, we tried transformer-based approaches (BERT classifier and Sentence Transformer Embeddings). \n",
    "\n",
    "We saw that out of these models transformer-based approaches were the best for this task.\n",
    "\n",
    "However, the other tried approaches could still be valuable, since they can be used together with other approaches. For example, we can use them to filter out dissimilar sentences and then use transformers to compare the remaining sentences.\n",
    "\n",
    "Lastly, we can take a look at the predictions of our models for some examples from the test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9d1511541217c098",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>bleu</th>\n",
       "      <th>word2vec</th>\n",
       "      <th>doc2vec</th>\n",
       "      <th>lda</th>\n",
       "      <th>bert</th>\n",
       "      <th>sentence_transformer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PCCW 's chief operating officer , Mike Butcher...</td>\n",
       "      <td>Current Chief Operating Officer Mike Butcher a...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The world 's two largest automakers said their...</td>\n",
       "      <td>Domestic sales at both GM and No. 2 Ford Motor...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>According to the federal Centers for Disease C...</td>\n",
       "      <td>The Centers for Disease Control and Prevention...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A tropical storm rapidly developed in the Gulf...</td>\n",
       "      <td>A tropical storm rapidly developed in the Gulf...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The company didn 't detail the costs of the re...</td>\n",
       "      <td>But company officials expect the costs of the ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The settling companies would also assign their...</td>\n",
       "      <td>Under the agreement , the settling companies w...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Air Commodore Quaife said the Hornets remained...</td>\n",
       "      <td>Air Commodore John Quaife said the security op...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A Washington County man may have the countys f...</td>\n",
       "      <td>The countys first and only human case of West ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Moseley and a senior aide delivered their summ...</td>\n",
       "      <td>General Moseley and a senior aide presented th...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The broader Standard &amp; Poor 's 500 Index &lt; .SP...</td>\n",
       "      <td>The technology-laced Nasdaq Composite Index .I...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence1  \\\n",
       "0  PCCW 's chief operating officer , Mike Butcher...   \n",
       "1  The world 's two largest automakers said their...   \n",
       "2  According to the federal Centers for Disease C...   \n",
       "3  A tropical storm rapidly developed in the Gulf...   \n",
       "4  The company didn 't detail the costs of the re...   \n",
       "5  The settling companies would also assign their...   \n",
       "6  Air Commodore Quaife said the Hornets remained...   \n",
       "7  A Washington County man may have the countys f...   \n",
       "8  Moseley and a senior aide delivered their summ...   \n",
       "9  The broader Standard & Poor 's 500 Index < .SP...   \n",
       "\n",
       "                                           sentence2  label  tfidf   bleu  \\\n",
       "0  Current Chief Operating Officer Mike Butcher a...   True   True   True   \n",
       "1  Domestic sales at both GM and No. 2 Ford Motor...   True   True   True   \n",
       "2  The Centers for Disease Control and Prevention...   True   True   True   \n",
       "3  A tropical storm rapidly developed in the Gulf...  False   True   True   \n",
       "4  But company officials expect the costs of the ...  False   True  False   \n",
       "5  Under the agreement , the settling companies w...   True   True   True   \n",
       "6  Air Commodore John Quaife said the security op...  False  False  False   \n",
       "7  The countys first and only human case of West ...   True   True  False   \n",
       "8  General Moseley and a senior aide presented th...   True   True   True   \n",
       "9  The technology-laced Nasdaq Composite Index .I...  False  False  False   \n",
       "\n",
       "   word2vec  doc2vec    lda   bert  sentence_transformer  \n",
       "0      True     True   True   True                  True  \n",
       "1      True     True   True   True                  True  \n",
       "2      True     True   True   True                  True  \n",
       "3      True    False   True   True                 False  \n",
       "4      True    False  False  False                 False  \n",
       "5      True     True   True   True                  True  \n",
       "6     False     True   True  False                 False  \n",
       "7      True    False   True  False                 False  \n",
       "8      True     True   True   True                  True  \n",
       "9      True    False   True  False                 False  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(test_dataset)\n",
    "df['label'] = test_dataset['label'].numpy().astype(bool)\n",
    "df.drop('idx', inplace=True, axis=1)\n",
    "df['tfidf'] = preds['tfidf'].numpy()\n",
    "df['bleu'] = preds['bleu'].numpy()\n",
    "df['word2vec'] = preds['word2vec'].numpy()\n",
    "df['doc2vec'] = preds['doc2vec'].numpy()\n",
    "df['lda'] = preds['lda'].numpy()\n",
    "df['bert'] = preds['bert'].numpy()\n",
    "df['sentence_transformer'] = preds['sentence_transformer'].numpy()\n",
    "df.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ebaea1f718bf754",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Other possible approaches\n",
    "Here are some ideas for other possible approaches:\n",
    "- [Universal Sentence Encoder](https://tfhub.dev/google/universal-sentence-encoder/4)\n",
    "- [LSA](https://en.wikipedia.org/wiki/Latent_semantic_analysis)\n",
    "- [Soft Cosine Similarity](https://radimrehurek.com/gensim/similarities/soft_cosine_tutorial.html)\n",
    "- [FastText](https://fasttext.cc/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c023dff4d9879902",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## References\n",
    "- [Sentence Transformers](https://www.sbert.net/)\n",
    "- [HuggingFace Transformers](https://huggingface.co/transformers/)\n",
    "- [Gensim](https://radimrehurek.com/gensim/)\n",
    "- [NLTK](https://www.nltk.org/)\n",
    "- [Scikit-learn](https://scikit-learn.org/stable/)\n",
    "- [Sentence Similarity Evaluation](https://huggingface.co/spaces/mteb/leaderboard)\n",
    "- [Microsoft Research Paraphrase Corpus](https://www.microsoft.com/en-us/download/details.aspx?id=52398)\n",
    "- [GLUE](https://gluebenchmark.com/)\n",
    "- [Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks](https://arxiv.org/abs/1908.10084)\n",
    "- [BAAI/bge-large-en-v1.5](https://huggingface.co/BAAI/bge-large-en-v1.5)\n",
    "- [Fine-tuning a model with the Trainer API](https://huggingface.co/learn/nlp-course/chapter3/3?fw=pt)\n",
    "- [HuggingFace Sentence Similarity](https://huggingface.co/tasks/sentence-similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
